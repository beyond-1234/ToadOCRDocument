<!DOCTYPE html>
<html>
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<title>对图像进行ZCA白化 - Toad OCR</title>
<meta name="description" content="Go语言开发的卷积神经网络OCR - 开放RPC接口供开发者使用 - 这是提供介绍和教程的网站">
<meta name="generator" content="Hugo 0.83.0" />
<link href="http://vjp.suvvm.work/index.xml" rel="alternate" type="application/rss+xml">
<link rel="canonical" href="http://vjp.suvvm.work/how-toad-ocr-work/zca/">
<link rel="stylesheet" href="http://vjp.suvvm.work/css/theme.min.css">
<script src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
<link rel="stylesheet" href="http://vjp.suvvm.work/css/chroma.min.css">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script src="http://vjp.suvvm.work/js/bundle.js"></script><style>
:root {}
</style>
<meta property="og:title" content="对图像进行ZCA白化" />
<meta property="og:description" content="一、理论讲解 一、PCA解决的问题 从一个简单的数据集开始 1、当只有属性1时 SampleA SampleB SampleC SampleD SampleE SampleF Attr1 10 11 8 3 2 1 可以将数据绘制在一个一维的坐标轴上 这里可以" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://vjp.suvvm.work/how-toad-ocr-work/zca/" /><meta property="og:image" content="http://vjp.suvvm.work/images/og-image.png"/><meta property="article:section" content="how-toad-ocr-work" />
<meta property="article:published_time" content="2021-05-07T17:57:33&#43;08:00" />
<meta property="article:modified_time" content="2021-05-07T17:57:33&#43;08:00" /><meta property="og:site_name" content="Hugo Techdoc Theme" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://vjp.suvvm.work/images/og-image.png"/>

<meta name="twitter:title" content="对图像进行ZCA白化"/>
<meta name="twitter:description" content="一、理论讲解 一、PCA解决的问题 从一个简单的数据集开始 1、当只有属性1时 SampleA SampleB SampleC SampleD SampleE SampleF Attr1 10 11 8 3 2 1 可以将数据绘制在一个一维的坐标轴上 这里可以"/>
<meta itemprop="name" content="对图像进行ZCA白化">
<meta itemprop="description" content="一、理论讲解 一、PCA解决的问题 从一个简单的数据集开始 1、当只有属性1时 SampleA SampleB SampleC SampleD SampleE SampleF Attr1 10 11 8 3 2 1 可以将数据绘制在一个一维的坐标轴上 这里可以"><meta itemprop="datePublished" content="2021-05-07T17:57:33&#43;08:00" />
<meta itemprop="dateModified" content="2021-05-07T17:57:33&#43;08:00" />
<meta itemprop="wordCount" content="3270"><meta itemprop="image" content="http://vjp.suvvm.work/images/og-image.png"/>
<meta itemprop="keywords" content="" /></head>
<body><div class="container"><header>
<h1>Toad OCR</h1><a href="https://github.com/suvvm/ToadOCRDocument" class="github"><i class="fab fa-github"></i></a>
<p class="description">Go语言开发的卷积神经网络OCR - 开放RPC接口供开发者使用 - 这是提供介绍和教程的网站</p>

</header>
<div class="global-menu">
<nav>
<ul>
<li><a href="/getting-start/">快速开始</a></li>
<li><a href="/tutorials/">使用讲解</a></li>
<li><a href="/about/">关于</a></li>
<li class="active"><a href="/how-toad-ocr-work/">Toad Ocr 如何运作</a></li>
<li><a href="/distributed-cluster/">分布式集群</a></li></ul>
</nav>
</div>
<div class="content-container">
<main><h1>对图像进行ZCA白化</h1>
<h2 id="一理论讲解">一、理论讲解</h2>
<h3 id="一pca解决的问题">一、PCA解决的问题</h3>
<p>从一个简单的数据集开始</p>
<h4 id="1当只有属性1时">1、当只有属性1时</h4>
<table>
<thead>
<tr>
<th></th>
<th>SampleA</th>
<th>SampleB</th>
<th>SampleC</th>
<th>SampleD</th>
<th>SampleE</th>
<th>SampleF</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Attr1</strong></td>
<td>10</td>
<td>11</td>
<td>8</td>
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>可以将数据绘制在一个一维的坐标轴上</p>
<p><img src="/images/PCA_1.png" alt="img"></p>
<p>这里可以发现针对属性1样本A、B、C有相对较高的值，样本D、E、F有相对较低的值。通过上图可以发现，样本A、B、C彼此之间的相似性要比它们与D、E、F高。</p>
<h4 id="2如果测量两个属性">2、如果测量两个属性</h4>
<table>
<thead>
<tr>
<th></th>
<th>SampleA</th>
<th>SampleB</th>
<th>SampleC</th>
<th>SampleD</th>
<th>SampleE</th>
<th>SampleF</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Attr1</strong></td>
<td>10</td>
<td>11</td>
<td>8</td>
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td><strong>Attr2</strong></td>
<td>6</td>
<td>4</td>
<td>5</td>
<td>3</td>
<td>2.8</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>可以将数据绘制在一个二维的坐标轴上</p>
<p><img src="/images/PCA_2.png" alt="img"></p>
<p>在张图中，属性1是x轴，属性2是y轴。通过观察上图依旧可以得出，样本A、B、C在右上侧聚集，样本D、E、F在左下侧聚集。</p>
<h4 id="3如果测量三个属性">3、如果测量三个属性</h4>
<table>
<thead>
<tr>
<th></th>
<th>SampleA</th>
<th>SampleB</th>
<th>SampleC</th>
<th>SampleD</th>
<th>SampleE</th>
<th>SampleF</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Attr1</strong></td>
<td>10</td>
<td>11</td>
<td>8</td>
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td><strong>Attr2</strong></td>
<td>6</td>
<td>4</td>
<td>5</td>
<td>3</td>
<td>2.8</td>
<td>1</td>
</tr>
<tr>
<td><strong>Attr3</strong></td>
<td>12</td>
<td>9</td>
<td>10</td>
<td>2.5</td>
<td>1.3</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>则需要在上图的基础上添加z轴，使之成为三维坐标轴</p>
<p><img src="/images/PCA_3.png" alt="img"></p>
<h4 id="4如果要测量四个属性">4、如果要测量四个属性</h4>
<table>
<thead>
<tr>
<th></th>
<th>SampleA</th>
<th>SampleB</th>
<th>SampleC</th>
<th>SampleD</th>
<th>SampleE</th>
<th>SampleF</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Attr1</strong></td>
<td>10</td>
<td>11</td>
<td>8</td>
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td><strong>Attr2</strong></td>
<td>6</td>
<td>4</td>
<td>5</td>
<td>3</td>
<td>2.8</td>
<td>1</td>
</tr>
<tr>
<td><strong>Attr3</strong></td>
<td>12</td>
<td>9</td>
<td>10</td>
<td>2.5</td>
<td>1.3</td>
<td>2</td>
</tr>
<tr>
<td><strong>Attr4</strong></td>
<td>5</td>
<td>7</td>
<td>6</td>
<td>2</td>
<td>4</td>
<td>7</td>
</tr>
</tbody>
</table>
<p>则无法再绘制数据。</p>
<p>​	四个属性需要四个维度，而PCA则是为了解决上述问题而出现的，使用PCA可以将三维、四维及其以上的更多数据降维绘制二维的PCA图，并告知使用者哪个属性对数据聚类最有价值。</p>
<p><img src="/images/PCA_4.png" alt="img"></p>
<h3 id="二pca原理解析">二、PCA原理解析</h3>
<p>​	如果要了解PCA功能以及工作原理，需要先回归只有两个属性的数据集。</p>
<table>
<thead>
<tr>
<th></th>
<th>SampleA</th>
<th>SampleB</th>
<th>SampleC</th>
<th>SampleD</th>
<th>SampleE</th>
<th>SampleF</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Attr1</strong></td>
<td>10</td>
<td>11</td>
<td>8</td>
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td><strong>Attr2</strong></td>
<td>6</td>
<td>4</td>
<td>5</td>
<td>3</td>
<td>2.8</td>
<td>1</td>
</tr>
</tbody>
</table>
<h4 id="1计算中心点">1、计算中心点</h4>
<p>​	首先，计算样本绘制的二维图像的中心点 ，即针对对应坐标轴所代表的每个样本的属性值求和后除以样本数量。
$$
m_x = \frac{\sum_{S=1}^nA_{1i}}{n} \\ m_y = \frac{\sum_{S=1}^nA_{2i}}{n}
$$</p>
<p>可以得到G(5.83,3.63)</p>
<p><img src="/images/PCA_6.png" alt="img"></p>
<p>移动数据，使得中心点G落在坐标轴原点上。</p>
<p><img src="/images/PCA_7.png" alt="img"></p>
<table>
<thead>
<tr>
<th></th>
<th>SampleA</th>
<th>SampleB</th>
<th>SampleC</th>
<th>SampleD</th>
<th>SampleE</th>
<th>SampleF</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Attr1</strong></td>
<td>4.17</td>
<td>5.17</td>
<td>2.17</td>
<td>-2.83</td>
<td>-3.83</td>
<td>-4.83</td>
</tr>
<tr>
<td><strong>Attr2</strong></td>
<td>2.37</td>
<td>0.37</td>
<td>1.37</td>
<td>-0.63</td>
<td>-0.83</td>
<td>-2.63</td>
</tr>
</tbody>
</table>
<h4 id="2计算pc1">2、计算PC1</h4>
<p>​	绘制一条穿过原点的随机直线，并旋转这条直线，使其在仍然穿过原点的情况下尽可能的拟合数据。</p>
<p><img src="/images/PCA_8.png" alt="img"></p>
<p>判定拟合度高低，为了量化穿过原点的直线拟合数据的程度，首先将所有数据投影到目标直线上</p>
<p><img src="/images/PCA_9.png" alt="img"></p>
<p>​	之后便可以测量各个样本点到目标直线的距离，并尝试找到使所有样本点到直线距离之和<strong>最小</strong>的直线，或者也可以尝试寻找所有投影点到原点的距离最之和大的直线，原因是当直线与数据更加拟合的时候，样本点到直线距离整体上会减小，而投影点到原点的整体距离则会增加。</p>
<p>​	针对每个单独的样本点来说，可以以原点、样本点、投影点，三点组成一个直角三角形，通过勾股定理可以得知，样本点到直线距离(边a)和投影点到原点的距离(边b)是逆相关的且$$ c^2 = a^2 + b^2 $$。样本点到原点的距离(边c)是不变的。所以PCA可以选择最小化样本与直线的距离或最大化投影到原点的距离。</p>
<p>​	不过显然投影点到原点更加方便计算，所以可以采用最大化投影点到原点的距离(d)的平方和($ SS_d $)。
$$
SS_d = \sum_{s=1}^nd_s^2
$$</p>
<p>​	这条线可以看作一条特殊的拟合直线。</p>
<h5 id="pca拟合直线">PCA拟合直线</h5>
<p>我们将输入数据  $ \left( \begin{array} {ccc} 4.17 &amp; 5.17 &amp; 2.17 &amp; -2.83 &amp; -3.83 &amp; -4.83  \\  2.37 &amp; 0.37 &amp; 1.37 &amp; -0.63 &amp; -0.83 &amp; -2.63 \end{array} \right) $  记为矩阵P</p>
<p>因为直线过原点只需考虑计算直线斜率，那么如果知道了直线的单位法向量$ \vec n(n_1, n_2) $   ，对于任意样本点 $ (x_s, y_s) $ 该点的坐标向量与直线法向量  的内积正好等于该点到直线的距离(同向为正, 反向为负)，即
$$
d_s =  \left(
\begin{array}
{ccc}
x_s\\<br>
y_s
\end{array}
\right) \cdot \vec n
$$</p>
<p>将距离带入距离公式 $ SS_d = \sum_{s=1}^nd_s^2 $</p>
<p>得到新的公式
$$
SS_d = \sum_{s=1}^n \left|\left( \begin{array} {ccc} x_s \\ y_s \end{array} \right) \cdot \vec n \right|^2 = \sum_{s=1}^n \vec n^T \left( \begin{array} {ccc} x_s \\ y_s \end{array} \right) （\begin{array} {ccc} x_s &amp; y_s \end{array}）\vec n = \vec n^T \sum_{s=1}^n \left( \begin{array} {ccc} x_s \\ y_s \end{array} \right) （\begin{array} {ccc} x_s &amp; y_s \end{array}）\vec n
$$</p>
<p>其中 $ \sum_{s=1}^n \left( \begin{array} {ccc} x_s \\ y_s \end{array} \right) （\begin{array} {ccc} x_s &amp; y_s \end{array}）= PP^T $   所以 $ SS_d = \vec n^TPP^T\vec n $  而 $ \frac{1}{n - 1}  PP^T $ 就是原始数据的协方差矩阵。</p>
<p>对矩阵P进行SVD奇异值分解
$$
P = U\Sigma V^T
$$</p>
<p>$$
PP^T	= U\Sigma V^T(U\Sigma V^T)^T
$$</p>
<p>$$
PP^T = U\Sigma V^TV\Sigma U^T
$$</p>
<p>$$
PP^T = V\Sigma \Sigma V^T \qquad or \qquad PP^T = U\Sigma \Sigma U^T
$$</p>
<p>$$
P^TPV = V\Sigma \Sigma \qquad or \qquad PP^TU = U\Sigma \Sigma
$$</p>
<p>$ PP^T $ 的特征向量
$$
P^TP \vec v_1 = \lambda_1 \vec v_1 \qquad P^TP \vec v_2 = \lambda_2 \vec v_2
$$
所以
$$
V = \vec v_1 \vec v_2
$$
而
$$
\Sigma = \left( \begin{array} {ccc} \sigma_1 &amp; 0 \\ 0 &amp; \sigma_2 \end{array} \right)
$$</p>
<p>$$
\Sigma \Sigma = \left( \begin{array} {ccc} \lambda_1 &amp; 0 \\ 0 &amp; \lambda_2 \end{array} \right)
$$</p>
<p>所以
$$
\lambda_1 = \sigma_1^2 \qquad \lambda_2 = \sigma_2^2
$$
直线的法向方向应该为$ PP^T $  最小特征值对应的特征方向。</p>
<p>得到了直线的法向量，便可以获得直线的斜率
$$
PP^T = \left( \begin{array} {ccc} 4.17 &amp; 5.17 &amp; 2.17 &amp; -2.83 &amp; -3.83 &amp; -4.83  \\  2.37 &amp; 0.37 &amp; 1.37 &amp; -0.63 &amp; -0.83 &amp; -2.63 \end{array} \right)
\left( \begin{array} {ccc} 2.37 &amp; 4.17 \\ 0.37 &amp; 5.17 \\ 1.37 &amp; 2.17 \\ -0.63 &amp; -2.83 \\ -0.83 &amp; -3.83 \\ -2.63 &amp; -4.83 \end{array} \right) =\left( \begin{array} {ccc} 32.43 &amp; 94.83 \\ 15.63 &amp; 32.43 \end{array} \right)
$$</p>
<p>$$
\lambda_1 = 65.52 对应特征向量 = \left( \begin{array} {ccc} 2.64 \\ 1 \end{array} \right)  \qquad \lambda_2 = -0.66 对应特征向量 = \left( \begin{array} {ccc} -2.64 \\ 1 \end{array} \right)
$$</p>
<p>所以斜率为0.264</p>
<h6 id="最小二乘数法无法计算pca拟合直线">最小二乘数法无法计算PCA拟合直线</h6>
<p>​	使用截距式表示上述直线，直线为ax + by = 0，由于上方直线过原点，所以截距b为0
$$
d = \frac{|ax_s + by_s|}{\sqrt {a^2 + b^2}}
$$</p>
<p>​	我们要使表达式 $ \sum_{s=1}^n[\frac{|ax_s + by_s|}{\sqrt {a^2 + b^2}}]^2 = \sum_{s=1}^n\frac{(ax_s + by_s)^2}{a^2 + b^2} $  的值最小</p>
<p>​	首先对a和b求偏导：
$$
\frac{\sigma}{\sigma a}\sum_{s=1}^n\frac{(ax_s + by_s)^2}{a^2 + b^2} \\<br>
= \sum_{s=1}^n\frac{2x_s(ax_s + by_s)(a^2 + b^2) - 2a(ax_s + by_s)^2}{(a^2 + b^2)^2}\\<br>
= \sum_{s=1}^n\frac{2x_s^2a^3 + 2bx_sy_sa^2 + 2x_s^2ab^2 + 2b^3x_sy_s - 2a^3x_s^2 - 4a^2bx_sy_s - 2ab^2y_s^2}{a^4 + 2a^2b^2 + b^4} \\<br>
= \sum_{s=1}^n\frac{-2bx_sy_s a^2 + 2b^2(x_s^2 - y_s^2)a + 2b^3x_sy_s}{a^4 + 2a^2b^2 + b^4}
$$</p>
<p>$$
\frac{\sigma}{\sigma b}\sum_{s=1}^n\frac{(ax_s + by_s)^2}{a^2 + b^2} \\<br>
= \sum_{s=1}^n\frac{2y_s(ax_s + by_s)(a^2 + b^2) - 2b(ax_s + by_s)^2}{(a^2 + b^2)^2} \\<br>
= \sum_{s=1}^n\frac{2a^3x_sy_s + 2a^2y_s^2b + 2ax_sy_sb^2 + 2y_s^2b^3 - 2a^2x_s^2b - 4ax_sy_sb^2 - 2y_s^2b^3}{a^4 + 2a^2b^2 + b^4} \\<br>
= \sum_{s=1}^n\frac{-2ax_sy_sb^2 + 2a^2(y_s^2 - x_s^2)b + 2a^3x_sy_s}{a^4 + 2a^2b^2 + b^4}
$$</p>
<p>得到下方方程组
$$
\begin{cases}
\sum_{s=1}^n\frac{-2ax_sy_sb^2 + 2a^2(y_s^2 - x_s^2)b + 2a^3x_sy_s}{a^4 + 2a^2b^2 + b^4} = 0 \\<br>
\sum_{s=1}^n\frac{-2bx_sy_s a^2 + 2b^2(x_s^2 - y_s^2)a + 2b^3x_sy_s}{a^4 + 2a^2b^2 + b^4} = 0
\end{cases}
$$
xy共轭，无法根据将上述方程组得到a与b的表达式，所以无法继续解得拟合直线。</p>
<p>​	最终得到的这条直线被称为主成份1(PC1) y = 0.264x，斜率为0.264</p>
<p><img src="/images/PCA_10.png" alt="img"></p>
<p>​	可以通过PC1的斜率得知属性1和属性2的线性组合为2.64:1，可以根据勾股定理求的属性1为3.1，属性2位1的样本点在PC1上，其到原点距离为，使用SVD计算PCA时将上述PC1方向样本缩放做标准化，使3.1作为单位长度等于1。最终得到属性1为 $ 2.64 \div 2.82 = 0.94 $属性2为 $ 1 \div 2.82 = 0.35 $ 最终得到PC1的特征向量$ \vec a = (0.94, 0.35) $，0.94与0.35则作为属性1与属性2的荷载得分。而上方的 $ SS_d $ 也就是PC1的特征值。</p>
<h4 id="3计算pc2">3、计算PC2</h4>
<p>​	经过原点做一条垂直于PC1的直线</p>
<p><img src="/images/PCA_11.png" alt="img"></p>
<p>​	同样适用SVD计算得到PC2的特征向量$ \vec b = (-0.35, 0.94) $ -0.35与0.94则作为属性1与属性2的荷载得分。</p>
<h4 id="4获得最终pca图">4、获得最终PCA图</h4>
<p>​	将PC1与PC2旋转至水平与垂直，作为新的坐标系</p>
<p><img src="/images/PCA_12.png" alt="img"></p>
<p>得到新的一组样本点</p>
<table>
<thead>
<tr>
<th></th>
<th>SampleA'</th>
<th>SampleB'</th>
<th>SampleC'</th>
<th>SampleD'</th>
<th>SampleE'</th>
<th>SampleF'</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Attr1</strong></td>
<td>4.74</td>
<td>4.97</td>
<td>2.51</td>
<td>-2.87</td>
<td>-3.88</td>
<td>-5.45</td>
</tr>
<tr>
<td><strong>Attr2</strong></td>
<td>0.74</td>
<td>-1.49</td>
<td>0.51</td>
<td>0.41</td>
<td>0.58</td>
<td>-0.75</td>
</tr>
</tbody>
</table>
<p>$$
SS_{dpc1} = \sum_{S'=1}^nd_{a1S'}^2 \\<br>
= 4.74^2 + 4.97^2 + 2.51^2 + (-2.87)^2 + (-3.88)^2 + (-5.45)^2 \\<br>
= 106.46 \\<br>
SS_{dpc1} = \sum_{S'=1}^nd_{a2S'}^2 \\<br>
= 0.74^2 + (-1.49)^2 + 0.51^2 + 0.41^2 + 0.58^2 + (-0.75)^2 \\<br>
= 4.09
$$</p>
<p>可以用上方的平方和除以样本点数量减一获得PC1与PC2围绕原点的的差异
$$
V_{PC1} = \frac{SS_{dpc1}}{6 - 1} = \frac{93.25}{5} = 21.29 \\<br>
V_{PC1} = \frac{SS_{dpc2}}{6 - 1} = \frac{4.05}{5} = 0.82
$$
最终通过计算得到碎石图所需数值
$$
PC1 = \frac{18.65}{18.65 + 0.81} = 0.962 = 96.2% \\<br>
PC2 = \frac{18.65}{18.65 + 0.81} = 0.038 = 3.8% \\<br>
$$</p>
<p><img src="/images/PCA_13.png" alt="img"></p>
<p>可以发现PC1可以96.2%的表示特征数据，可以使用PC1作为主轴将上述数据降低为一维矩阵</p>
<h3 id="三zca白化">三、ZCA白化</h3>
<p>​	<strong>ZCA白化必须先进行PCA</strong></p>
<p>​	首先将目标n维特征映射到k维上，但此时得到的数据已经被降为k纬度，但是对于图像处理来说，输入的特征矩阵就是像素矩阵，我们希望原图像维度不变，这时则需要对PCA处理完的数据进行旋转，将维度旋转回原先的n维，使得最终得到的数据尽可能的接近原始数据。</p>
<p>​	即  $ X_{ZCA} = UX_{PCA} $</p>
<h2 id="二代码实现">二、代码实现</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#75715e">// ZCA 零相位成分分析(zca)函数
</span><span style="color:#75715e">// zca函数作用类似与主成分分析(pca)
</span><span style="color:#75715e">// 首先进行pca主成分分析，将图像像素点张量作为特征进行数据降维
</span><span style="color:#75715e">// 之后在将pca降维后的数据进行旋转，使得最终数据维度与原始数据维度相同
</span><span style="color:#75715e">// 具体理论见toadOCRDocument中关于ZCA白化的描述
</span><span style="color:#75715e">//
</span><span style="color:#75715e">// 入参
</span><span style="color:#75715e">//	data tensor.Tensor	// 图像像素点张量
</span><span style="color:#75715e">//
</span><span style="color:#75715e">// 返回
</span><span style="color:#75715e">//	tensor.Tensor		// ZCA白化后的张量
</span><span style="color:#75715e">//	error				// 错误信息
</span><span style="color:#75715e"></span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">ZCA</span>(<span style="color:#a6e22e">data</span> <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">Tensor</span>) (<span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">Tensor</span>, <span style="color:#66d9ef">error</span>) {
	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">dataTranspose</span>, <span style="color:#a6e22e">dataClone</span>, <span style="color:#a6e22e">sigma</span> <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">Tensor</span>	<span style="color:#75715e">// data转置 data备份 矩阵Σ(定义详见上述链接)
</span><span style="color:#75715e"></span>	<span style="color:#a6e22e">dataClone</span> = <span style="color:#a6e22e">data</span>.<span style="color:#a6e22e">Clone</span>().(<span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">Tensor</span>)
	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">Centralization</span>(<span style="color:#a6e22e">dataClone</span>); <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {	<span style="color:#75715e">// 对备份数据张量进行中心化操作
</span><span style="color:#75715e"></span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
	}
	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">err</span> <span style="color:#66d9ef">error</span>
	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">dataTranspose</span>, <span style="color:#a6e22e">err</span> =  <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">T</span>(<span style="color:#a6e22e">dataClone</span>); <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {	<span style="color:#75715e">// 求得中心化完成后的矩阵的转置
</span><span style="color:#75715e"></span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
	}
	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">sigma</span>, <span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">MatMul</span>(<span style="color:#a6e22e">dataTranspose</span>, <span style="color:#a6e22e">dataClone</span>); <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {	<span style="color:#75715e">// 求矩阵Σ
</span><span style="color:#75715e"></span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
	}
	<span style="color:#a6e22e">cols</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">sigma</span>.<span style="color:#a6e22e">Shape</span>()[<span style="color:#ae81ff">1</span>]	<span style="color:#75715e">// 获取矩阵Σ列数
</span><span style="color:#75715e"></span>	<span style="color:#75715e">// 对矩阵Σ逐元素处以列数-1，并覆盖原矩阵Σ，最终得到协方差矩阵
</span><span style="color:#75715e"></span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">Div</span>(<span style="color:#a6e22e">sigma</span>, float64(<span style="color:#a6e22e">cols</span><span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>), <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">UseUnsafe</span>()); <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
	}
	<span style="color:#75715e">// S特征值矩阵 U特征向量矩阵 V=U‘ 奇异值分解后的V这里用不到
</span><span style="color:#75715e"></span>	<span style="color:#a6e22e">S</span>, <span style="color:#a6e22e">U</span>, <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">sigma</span>.(<span style="color:#f92672">*</span><span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">Dense</span>).<span style="color:#a6e22e">SVD</span>(<span style="color:#66d9ef">true</span>,<span style="color:#66d9ef">true</span>)	<span style="color:#75715e">// 对协方差矩阵执行奇异值分解
</span><span style="color:#75715e"></span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
	}
	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">diag</span>, <span style="color:#a6e22e">UTranspose</span>, <span style="color:#a6e22e">tmp</span> <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">Tensor</span>
	<span style="color:#75715e">// 规则化项epsilon取0.1 求平方根倒数得对角阵diag
</span><span style="color:#75715e"></span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">diag</span>, <span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">S</span>.<span style="color:#a6e22e">Apply</span>(<span style="color:#a6e22e">InverseSqrt</span>(<span style="color:#ae81ff">0.1</span>), <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">UseUnsafe</span>()); <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
	}
	<span style="color:#a6e22e">diag</span> = <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">New</span>(<span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">AsDenseDiag</span>(<span style="color:#a6e22e">diag</span>))
	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">UTranspose</span>, <span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">T</span>(<span style="color:#a6e22e">U</span>); <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {	<span style="color:#75715e">// 计算U的转置
</span><span style="color:#75715e"></span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
	}
	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">tmp</span>, <span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">MatMul</span>(<span style="color:#a6e22e">U</span>, <span style="color:#a6e22e">diag</span>); <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
	}
	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">tmp</span>, <span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">MatMul</span>(<span style="color:#a6e22e">tmp</span>, <span style="color:#a6e22e">UTranspose</span>); <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
	}
	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">tmp</span>.<span style="color:#a6e22e">T</span>(); <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
	}
	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">tensor</span>.<span style="color:#a6e22e">MatMul</span>(<span style="color:#a6e22e">data</span>, <span style="color:#a6e22e">tmp</span>)
}
</code></pre></div><div class="edit-meta">
Last updated on 7 May 2021


<br>
Published on 7 May 2021
<br><a href="https://github.com/suvvm/ToadOCRDocument/edit/master/content/how-toad-ocr-work/zca.md" class="edit-page"><i class="fas fa-pen-square"></i>&nbsp;Edit on GitHub</a></div><nav class="pagination"><a class="nav nav-prev" href="http://vjp.suvvm.work/how-toad-ocr-work/data-load/" title="数据集加载"><i class="fas fa-arrow-left" aria-hidden="true"></i>&nbsp;Prev - 数据集加载</a>
<a class="nav nav-next" href="http://vjp.suvvm.work/how-toad-ocr-work/cnn/" title="卷积神经网络">Next - 卷积神经网络 <i class="fas fa-arrow-right" aria-hidden="true"></i></a>
</nav><footer><p class="powered">Powered by <a href="https://gohugo.io">Hugo</a>. Theme by <a href="https://themes.gohugo.io/hugo-theme-techdoc/">TechDoc</a>. Designed by <a href="https://github.com/thingsym/hugo-theme-techdoc">Thingsym</a>.</p>
</footer>
</main>
<div class="sidebar">

<nav class="open-menu">
<ul>
<li class=""><a href="http://vjp.suvvm.work">Home</a></li>

<li class=""><a href="http://vjp.suvvm.work/getting-start/">快速开始</a>
  
<ul class="sub-menu">
<li class=""><a href="http://vjp.suvvm.work/getting-start/use-http-client/">使用Toad OCR http客户端</a></li>
<li class=""><a href="http://vjp.suvvm.work/getting-start/contribut-doc/">为开源文档做贡献</a></li>
<li class=""><a href="http://vjp.suvvm.work/getting-start/tags-map/">标签对照</a></li>
</ul>
  
</li>

<li class=""><a href="http://vjp.suvvm.work/tutorials/">使用讲解</a>
  
<ul class="sub-menu">
<li class=""><a href="http://vjp.suvvm.work/tutorials/install-dependencies/">服务器环境搭建</a></li>
<li class=""><a href="http://vjp.suvvm.work/tutorials/use-client/">使用RPC客户端</a></li>
</ul>
  
</li>

<li class=""><a href="http://vjp.suvvm.work/about/">关于</a>
  
</li>

<li class=""><a href="http://vjp.suvvm.work/distributed-cluster/">分布式集群</a>
  
<ul class="sub-menu">
<li class=""><a href="http://vjp.suvvm.work/distributed-cluster/etcd-register-resolver/">Etcd gRPC 服务注册与服务发现</a></li>
<li class=""><a href="http://vjp.suvvm.work/distributed-cluster/cluster-construction/">集群搭建</a></li>
<li class=""><a href="http://vjp.suvvm.work/distributed-cluster/toad-ocr-preprocessor-server/">图像预处理服务部署</a></li>
<li class=""><a href="http://vjp.suvvm.work/distributed-cluster/toad-ocr-engine-server/">OCR识别服务节点部署</a></li>
<li class=""><a href="http://vjp.suvvm.work/distributed-cluster/proxy-china/">中国大陆服务器代理</a></li>
<li class=""><a href="http://vjp.suvvm.work/distributed-cluster/environment-construction/">服务器环境搭建</a></li>
</ul>
  
</li>

<li class="parent"><a href="http://vjp.suvvm.work/how-toad-ocr-work/">Toad Ocr 如何运作</a>
  
<ul class="sub-menu">
<li class=""><a href="http://vjp.suvvm.work/how-toad-ocr-work/persistence/">神经网络权重持久化与恢复</a></li>
<li class=""><a href="http://vjp.suvvm.work/how-toad-ocr-work/visualize/">图像可视化</a></li>
<li class=""><a href="http://vjp.suvvm.work/how-toad-ocr-work/data-load/">数据集加载</a></li>
<li class="active"><a href="http://vjp.suvvm.work/how-toad-ocr-work/zca/">对图像进行ZCA白化</a></li>
<li class=""><a href="http://vjp.suvvm.work/how-toad-ocr-work/cnn/">卷积神经网络</a></li>
<li class=""><a href="http://vjp.suvvm.work/how-toad-ocr-work/snn/">脉冲神经网络</a></li>
</ul>
  
</li>
</ul>
</nav>



<div class="sidebar-footer"></div>
</div>

</div><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/javascript">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>
</div>
</body>
</html>
